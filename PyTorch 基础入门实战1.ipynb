{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "colored-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此时，loss 关于 w 的偏导为: tensor(-2.)\n",
      "此时，loss 关于x的偏导为： tensor(-2.)\n",
      "此时，loss 关于y的偏导为： tensor(2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#forward ; loss = (w*x-y)^2\n",
    "def forward(x, y, w):\n",
    "    # 其中 x,y 为输入数据，w为该函数所需要的参数\n",
    "    y_predicted = w * x\n",
    "    loss = (y_predicted - y)**2\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "forward(x, y, w)  # (2-1)²=1\n",
    "x = torch.tensor(1.0,requires_grad=True)\n",
    "y = torch.tensor(2.0,requires_grad=True)\n",
    "# 将需要求取的 w 设置为可偏导\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "loss = forward(x, y, w)  # 计算损失\n",
    "loss.backward()  # 反向传播，计算梯度\n",
    "print(\"此时，loss 关于 w 的偏导为:\", w.grad)\n",
    "print(\"此时，loss 关于x的偏导为：\",x.grad)\n",
    "print(\"此时，loss 关于y的偏导为：\",y.grad)\n",
    "w.grad.zero_()  # 得到偏导后，清空梯度\n",
    "x.grad.zero_()\n",
    "y.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spatial-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(y, y_pred)= 0.5\n",
      "gradient(x, y, 2)= 7.0\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506905\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228092\n",
      "epoch 27: w = 1.975, loss = 0.00641072\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 所有点的预测值和实际值的距离的平方和，再取平均值（这种距离叫做欧氏距离）。\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "#测试代码\n",
    "y_pred = np.array([1,2])\n",
    "y = np.array([1,1])\n",
    "print('loss(y, y_pred)=',loss(y, y_pred))\n",
    "\n",
    "#手动计算梯度\n",
    "#返回dJ/dw\n",
    "def gradient(x, y, w):\n",
    "    return np.mean(2*w*x*x-2*x*y)\n",
    "## 测试代码\n",
    "x = np.array([1,2])\n",
    "y = np.array([1,1])\n",
    "print('gradient(x, y, 2)=',gradient(x, y, 2))\n",
    "\n",
    "# 正向传播，计算预测值\n",
    "def forward(x):\n",
    "    return w * x\n",
    "# 定义数据集合和 w 的初始化\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "w = 0.0\n",
    "# 定义步长和迭代次数\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    #计算损失\n",
    "    l = loss(Y, y_pred)\n",
    "    #计算梯度\n",
    "    dw = gradient(X, Y, w)\n",
    "    #更新权重 w\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-pottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228084\n",
      "epoch 27: w = 1.975, loss = 0.00641066\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "#Torch计算梯度\n",
    "import torch\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "#初始化张量 w\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "# 定义步长和迭代次数\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    # 无需定义梯度求解的函数，直接求解梯度\n",
    "    l.backward()\n",
    "    # 利用梯度下降更新参数\n",
    "    with torch.no_grad():\n",
    "        # w.grad :返回 w 的梯度\n",
    "        w.data -= learning_rate * w.grad\n",
    "    \n",
    "    # 清空梯度\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technological-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre= tensor([0., 0., 0., 0.], grad_fn=<MulBackward0>)\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228084\n",
      "epoch 27: w = 1.975, loss = 0.00641066\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "#Torch 定义的损失函数\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 初始化数据集\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    # 正向传播函数\n",
    "    return w * x\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "# 测试代码\n",
    "pre = forward(X)\n",
    "print('pre=',pre)\n",
    "for epoch in range(n_iters):\n",
    "    loss = nn.MSELoss()\n",
    "    l = loss(forward(X), Y)\n",
    "    l.backward()\n",
    "    # 利用梯度下降更新参数\n",
    "    with torch.no_grad():\n",
    "        # w.grad :返回 w 的梯度\n",
    "        w.data -= learning_rate * w.grad\n",
    "    \n",
    "    # 清空梯度\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')\n",
    "# 这里使用均方差损失计算预测值和真实值之间的距离\n",
    "#loss = nn.MSELoss()\n",
    "# 测试此时的损失\n",
    "#loss(forward(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MeanBackward0>)\n",
      "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MeanBackward0>)\n",
      "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MeanBackward0>)\n",
      "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MeanBackward0>)\n",
      "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MeanBackward0>)\n",
      "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MeanBackward0>)\n",
      "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MeanBackward0>)\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 10.000\n"
     ]
    }
   ],
   "source": [
    "#Torch 定义损失和优化器\n",
    "# 初始化数据集\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "# 模型的训练过程\n",
    "for epoch in range(n_iters):\n",
    "    y_predicted = forward(X)\n",
    "    # 计算损失\n",
    "    l = loss(Y, y_predicted)\n",
    "    # 计算梯度\n",
    "    l.backward()\n",
    "    # 更新权重，即向梯度方向走一步，类似于w.data -= learning_rate * w.grad\n",
    "    optimizer.step()\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
    "\n",
    "\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')\n",
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "总结一下，我们可以将一个线性问题的求解分为下面三个步骤：\n",
    "\n",
    "1. 定义模型（即正向传播函数）。\n",
    "2. 定义损失和优化器。\n",
    "3. 模型的训练（正向传播、反向传播、更新梯度、梯度下降、循环）。\n",
    "\n",
    "可以看到其实模型训练的步骤是固定的:\n",
    "1. 利用 nn.Linear 定义模型。\n",
    "2. 利用 nn.MSELoss 定义损失。\n",
    "3. 利用 torch.optim 定义优化器。\n",
    "4. 利用梯度下降算法进行模型的训练。\n",
    "\n",
    "并且模型的训练步骤也是固定的：\n",
    "1. 利用 model(X) 进行正向传播。\n",
    "2. 利用 loss(Y, y_predicted) 计算模型损失。\n",
    "3. 利用 loss.backward() 计算模型梯度。\n",
    "4. 利用 optimizer.step() 更新权重。\n",
    "5. 利用 optimizer.zero_grad() 清空梯度。\n",
    "6. 重复 1-5 的操作。\n",
    "因此，使用 PyTorch 可以大大的简化我们的编程难度。我们只需要改变模型的形式、损失函数的形式、优化器的形式以及各个参数的值，\n",
    "就能够训练出不同的模型，进而解决不同的深度学习问题了。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-notion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1]) torch.Size([4, 1])\n",
      "model =  Linear(in_features=1, out_features=1, bias=True)\n",
      "optimizer =  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch  1 : w =  3.142615795135498  loss =  tensor(48.8098, grad_fn=<MeanBackward0>)\n",
      "epoch  11 : w =  1.7419989109039307  loss =  tensor(0.1416, grad_fn=<MeanBackward0>)\n",
      "epoch  21 : w =  1.7895342111587524  loss =  tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "epoch  31 : w =  1.8443334102630615  loss =  tensor(0.0372, grad_fn=<MeanBackward0>)\n",
      "epoch  41 : w =  1.8851287364959717  loss =  tensor(0.0202, grad_fn=<MeanBackward0>)\n",
      "epoch  51 : w =  1.9152377843856812  loss =  tensor(0.0110, grad_fn=<MeanBackward0>)\n",
      "epoch  61 : w =  1.9374550580978394  loss =  tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "epoch  71 : w =  1.9538488388061523  loss =  tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "epoch  81 : w =  1.9659456014633179  loss =  tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "epoch  91 : w =  1.9748717546463013  loss =  tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "根据训练模型预测，当 x =5 时，y 的值为： tensor([[9.9044]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Torch一个完整的例子\n",
    "#正向传播，计算预测值\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# 由于使用 PyTorch ，因此所有的变量都为张量\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# 1. 定义模型\n",
    "n_samples, n_features = X.shape\n",
    "# 这里输入和输出的维度相同\n",
    "model = nn.Linear(n_features, n_features)\n",
    "print('model = ', model)\n",
    "\n",
    "# 2. 定义优化器和损失函数\n",
    "learning_rate = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# 在定义优化器时，直接利用 model.parameters() 表示模型中所有需要求的权重\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('optimizer = ', optimizer)\n",
    "\n",
    "# 3. 模型的训练，固定的步骤：正向传播、计算损失、反向传播、更新权重、梯度清空\n",
    "for epoch in range(n_iters):\n",
    "    # 正向传播\n",
    "    y_predicted = model(X)\n",
    "    # 损失\n",
    "    l = loss(Y, y_predicted)\n",
    "    # 反向传播\n",
    "    l.backward()\n",
    "    # 更新权重\n",
    "    optimizer.step()\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()  # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为：', forward(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n",
      "100 1 1\n",
      "model= Linear(in_features=1, out_features=1, bias=True)\n",
      "optimizer =  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#实战 线性回归\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#挑战\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(\n",
    "    n_samples=100, n_features=1, noise=20, random_state=4)\n",
    "print(X_numpy.shape,y_numpy.shape)\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "\n",
    "# 编写代码处\n",
    "X=torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y=y.view(y.shape[0],1)\n",
    "\n",
    "# 测试代码\n",
    "X.size(), y.size()\n",
    "### 补充代码 ###\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 测试代码\n",
    "print(n_samples,input_size,output_size)\n",
    "print('model=',model)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# 在定义优化器时，直接利用 model.parameters() 表示模型中所有需要求的权重\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('optimizer = ', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "essential-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 413.1164\n",
      "epoch: 20, loss = 292.0517\n",
      "epoch: 30, loss = 290.1894\n",
      "epoch: 40, loss = 290.1602\n",
      "epoch: 50, loss = 290.1598\n",
      "epoch: 60, loss = 290.1598\n",
      "epoch: 70, loss = 290.1597\n",
      "epoch: 80, loss = 290.1597\n",
      "epoch: 90, loss = 290.1597\n",
      "epoch: 100, loss = 290.1597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "for epoch in range(n_iters):\n",
    "    # Forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    l = loss(y_predicted, y) \n",
    "    # Backward pass and update\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {l.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
