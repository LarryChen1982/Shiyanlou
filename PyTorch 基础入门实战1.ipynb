{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "colored-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此时，loss 关于 w 的偏导为: tensor(-2.)\n",
      "此时，loss 关于x的偏导为： tensor(-2.)\n",
      "此时，loss 关于y的偏导为： tensor(2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#forward ; loss = (w*x-y)^2\n",
    "def forward(x, y, w):\n",
    "    # 其中 x,y 为输入数据，w为该函数所需要的参数\n",
    "    y_predicted = w * x\n",
    "    loss = (y_predicted - y)**2\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "forward(x, y, w)  # (2-1)²=1\n",
    "x = torch.tensor(1.0,requires_grad=True)\n",
    "y = torch.tensor(2.0,requires_grad=True)\n",
    "# 将需要求取的 w 设置为可偏导\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "loss = forward(x, y, w)  # 计算损失\n",
    "loss.backward()  # 反向传播，计算梯度\n",
    "print(\"此时，loss 关于 w 的偏导为:\", w.grad)\n",
    "print(\"此时，loss 关于x的偏导为：\",x.grad)\n",
    "print(\"此时，loss 关于y的偏导为：\",y.grad)\n",
    "w.grad.zero_()  # 得到偏导后，清空梯度\n",
    "x.grad.zero_()\n",
    "y.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "spatial-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(y, y_pred)= 0.5\n",
      "gradient(x, y, 2)= 7.0\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506905\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228092\n",
      "epoch 27: w = 1.975, loss = 0.00641072\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 所有点的预测值和实际值的距离的平方和，再取平均值（这种距离叫做欧氏距离）。\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "#测试代码\n",
    "y_pred = np.array([1,2])\n",
    "y = np.array([1,1])\n",
    "print('loss(y, y_pred)=',loss(y, y_pred))\n",
    "\n",
    "#手动计算梯度\n",
    "#返回dJ/dw\n",
    "def gradient(x, y, w):\n",
    "    return np.mean(2*w*x*x-2*x*y)\n",
    "## 测试代码\n",
    "x = np.array([1,2])\n",
    "y = np.array([1,1])\n",
    "print('gradient(x, y, 2)=',gradient(x, y, 2))\n",
    "\n",
    "# 正向传播，计算预测值\n",
    "def forward(x):\n",
    "    return w * x\n",
    "# 定义数据集合和 w 的初始化\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "w = 0.0\n",
    "# 定义步长和迭代次数\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    #计算损失\n",
    "    l = loss(Y, y_pred)\n",
    "    #计算梯度\n",
    "    dw = gradient(X, Y, w)\n",
    "    #更新权重 w\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "skilled-pottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228084\n",
      "epoch 27: w = 1.975, loss = 0.00641066\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "#Torch计算梯度\n",
    "import torch\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "#初始化张量 w\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "# 定义步长和迭代次数\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "for epoch in range(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y, y_pred)\n",
    "    # 无需定义梯度求解的函数，直接求解梯度\n",
    "    l.backward()\n",
    "    # 利用梯度下降更新参数\n",
    "    with torch.no_grad():\n",
    "        # w.grad :返回 w 的梯度\n",
    "        w.data -= learning_rate * w.grad\n",
    "    \n",
    "    # 清空梯度\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "technological-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre= tensor([0., 0., 0., 0.], grad_fn=<MulBackward0>)\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 23: w = 1.952, loss = 0.02352631\n",
      "epoch 25: w = 1.966, loss = 0.01228084\n",
      "epoch 27: w = 1.975, loss = 0.00641066\n",
      "epoch 29: w = 1.982, loss = 0.00334642\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 9.924\n"
     ]
    }
   ],
   "source": [
    "#Torch 定义的损失函数\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 初始化数据集\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    # 正向传播函数\n",
    "    return w * x\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 30\n",
    "# 测试代码\n",
    "pre = forward(X)\n",
    "print('pre=',pre)\n",
    "for epoch in range(n_iters):\n",
    "    loss = nn.MSELoss()\n",
    "    l = loss(forward(X), Y)\n",
    "    l.backward()\n",
    "    # 利用梯度下降更新参数\n",
    "    with torch.no_grad():\n",
    "        # w.grad :返回 w 的梯度\n",
    "        w.data -= learning_rate * w.grad\n",
    "    \n",
    "    # 清空梯度\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')\n",
    "# 这里使用均方差损失计算预测值和真实值之间的距离\n",
    "#loss = nn.MSELoss()\n",
    "# 测试此时的损失\n",
    "#loss(forward(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "artificial-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward>)\n",
      "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward>)\n",
      "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward>)\n",
      "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward>)\n",
      "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward>)\n",
      "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward>)\n",
      "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward>)\n",
      "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward>)\n",
      "根据训练模型预测，当 x =5 时，y 的值为： 10.000\n"
     ]
    }
   ],
   "source": [
    "#Torch 定义损失和优化器\n",
    "# 初始化数据集\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "# 模型的训练过程\n",
    "for epoch in range(n_iters):\n",
    "    y_predicted = forward(X)\n",
    "    # 计算损失\n",
    "    l = loss(Y, y_predicted)\n",
    "    # 计算梯度\n",
    "    l.backward()\n",
    "    # 更新权重，即向梯度方向走一步，类似于w.data -= learning_rate * w.grad\n",
    "    optimizer.step()\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
    "\n",
    "\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为： {forward(5):.3f}')\n",
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "总结一下，我们可以将一个线性问题的求解分为下面三个步骤：\n",
    "\n",
    "1. 定义模型（即正向传播函数）。\n",
    "2. 定义损失和优化器。\n",
    "3. 模型的训练（正向传播、反向传播、更新梯度、梯度下降、循环）。\n",
    "\n",
    "可以看到其实模型训练的步骤是固定的:\n",
    "1. 利用 nn.Linear 定义模型。\n",
    "2. 利用 nn.MSELoss 定义损失。\n",
    "3. 利用 torch.optim 定义优化器。\n",
    "4. 利用梯度下降算法进行模型的训练。\n",
    "\n",
    "并且模型的训练步骤也是固定的：\n",
    "1. 利用 model(X) 进行正向传播。\n",
    "2. 利用 loss(Y, y_predicted) 计算模型损失。\n",
    "3. 利用 loss.backward() 计算模型梯度。\n",
    "4. 利用 optimizer.step() 更新权重。\n",
    "5. 利用 optimizer.zero_grad() 清空梯度。\n",
    "6. 重复 1-5 的操作。\n",
    "因此，使用 PyTorch 可以大大的简化我们的编程难度。我们只需要改变模型的形式、损失函数的形式、优化器的形式以及各个参数的值，\n",
    "就能够训练出不同的模型，进而解决不同的深度学习问题了。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "amber-notion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1]) torch.Size([4, 1])\n",
      "model =  Linear(in_features=1, out_features=1, bias=True)\n",
      "optimizer =  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "epoch  1 : w =  3.2500979900360107  loss =  tensor(25.8055, grad_fn=<MseLossBackward>)\n",
      "epoch  11 : w =  2.1203315258026123  loss =  tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "epoch  21 : w =  2.0741567611694336  loss =  tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "epoch  31 : w =  2.054452657699585  loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "epoch  41 : w =  2.040174722671509  loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "epoch  51 : w =  2.02964448928833  loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "epoch  61 : w =  2.02187442779541  loss =  tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "epoch  71 : w =  2.0161406993865967  loss =  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "epoch  81 : w =  2.0119102001190186  loss =  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch  91 : w =  2.0087883472442627  loss =  tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "根据训练模型预测，当 x =5 时，y 的值为： tensor([[10.0334]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Torch一个完整的例子\n",
    "#正向传播，计算预测值\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# 由于使用 PyTorch ，因此所有的变量都为张量\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# 1. 定义模型\n",
    "n_samples, n_features = X.shape\n",
    "# 这里输入和输出的维度相同\n",
    "model = nn.Linear(n_features, n_features)\n",
    "print('model = ', model)\n",
    "\n",
    "# 2. 定义优化器和损失函数\n",
    "learning_rate = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# 在定义优化器时，直接利用 model.parameters() 表示模型中所有需要求的权重\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('optimizer = ', optimizer)\n",
    "\n",
    "# 3. 模型的训练，固定的步骤：正向传播、计算损失、反向传播、更新权重、梯度清空\n",
    "for epoch in range(n_iters):\n",
    "    # 正向传播\n",
    "    y_predicted = model(X)\n",
    "    # 损失\n",
    "    l = loss(Y, y_predicted)\n",
    "    # 反向传播\n",
    "    l.backward()\n",
    "    # 更新权重\n",
    "    optimizer.step()\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()  # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'根据训练模型预测，当 x =5 时，y 的值为：', forward(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "metropolitan-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n",
      "100 1 1\n",
      "model= Linear(in_features=1, out_features=1, bias=True)\n",
      "optimizer =  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#实战 线性回归\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#挑战\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(\n",
    "    n_samples=100, n_features=1, noise=20, random_state=4)\n",
    "print(X_numpy.shape,y_numpy.shape)\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "\n",
    "# 编写代码处\n",
    "X=torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y=y.view(y.shape[0],1)\n",
    "\n",
    "# 测试代码\n",
    "X.size(), y.size()\n",
    "### 补充代码 ###\n",
    "n_samples, n_features = X.shape\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 测试代码\n",
    "print(n_samples,input_size,output_size)\n",
    "print('model=',model)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# 在定义优化器时，直接利用 model.parameters() 表示模型中所有需要求的权重\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('optimizer = ', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "essential-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 409.0306\n",
      "epoch: 20, loss = 291.9953\n",
      "epoch: 30, loss = 290.1886\n",
      "epoch: 40, loss = 290.1602\n",
      "epoch: 50, loss = 290.1597\n",
      "epoch: 60, loss = 290.1598\n",
      "epoch: 70, loss = 290.1597\n",
      "epoch: 80, loss = 290.1597\n",
      "epoch: 90, loss = 290.1598\n",
      "epoch: 100, loss = 290.1597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "for epoch in range(n_iters):\n",
    "    # Forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    l = loss(y_predicted, y) \n",
    "    # Backward pass and update\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {l.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
