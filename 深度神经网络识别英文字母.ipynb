{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "internal-assets",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, name, batch_size):  # 数据所在的文件名name和batch中图片的数量batch_size\n",
    "        with open(name, 'rb') as f:\n",
    "            data = np.load(f, allow_pickle=True)\n",
    "        self.x = data[0]  # 输入x\n",
    "        self.y = data[1]  # 预期正确输出y\n",
    "        self.l = len(self.x)\n",
    "        self.batch_size = batch_size\n",
    "        self.pos = 0  # pos用来记录数据读取的位置\n",
    "\n",
    "    def forward(self):\n",
    "        pos = self.pos\n",
    "        bat = self.batch_size\n",
    "        l = self.l\n",
    "        if pos + bat >= l:  # 已经是最后一个batch时，返回剩余的数据，并设置pos为开始位置0\n",
    "            ret = (self.x[pos:l], self.y[pos:l])\n",
    "            self.pos = 0\n",
    "            #print(l)\n",
    "            index = list(range(l))\n",
    "            np.random.shuffle(index)  # 将训练数据打乱\n",
    "            self.x = self.x[index]\n",
    "            self.y = self.y[index]\n",
    "        else:  # 不是最后一个batch, pos直接加上batch_size\n",
    "            ret = (self.x[pos:pos + bat], self.y[pos:pos + bat])\n",
    "            self.pos += self.batch_size\n",
    "\n",
    "        return ret, self.pos  # 返回的pos为0时代表一个epoch已经结束\n",
    "\n",
    "    def backward(self, d):  # 数据层无backward操作\n",
    "        pass\n",
    "\n",
    "\n",
    "class FullyConnect:\n",
    "    def __init__(self, l_x, l_y):  # 两个参数分别为输入层的长度和输出层的长度\n",
    "        # 使用随机数初始化参数，请暂时忽略这里为什么多了np.sqrt(l_x)\n",
    "        self.weights = np.random.randn(l_y, l_x) / np.sqrt(l_x)\n",
    "        self.bias = np.random.randn(l_y, 1)  # 使用随机数初始化参数\n",
    "        self.lr = 0  # 先将学习速率初始化为0，最后统一设置学习速率\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x  # 把中间结果保存下来，以备反向传播时使用\n",
    "        self.y = np.array([np.dot(self.weights, xx) +\n",
    "                           self.bias for xx in x])  # 计算全连接层的输出\n",
    "        return self.y  # 将这一层计算的结果向前传递\n",
    "\n",
    "    def backward(self, d):\n",
    "        # 根据链式法则，将反向传递回来的导数值乘以x，得到对参数的梯度\n",
    "        ddw = [np.dot(dd, xx.T) for dd, xx in zip(d, self.x)]\n",
    "        self.dw = np.sum(ddw, axis=0) / self.x.shape[0]\n",
    "        self.db = np.sum(d, axis=0) / self.x.shape[0]\n",
    "        self.dx = np.array([np.dot(self.weights.T, dd) for dd in d])\n",
    "\n",
    "        # 更新参数\n",
    "        self.weights -= self.lr * self.dw\n",
    "        self.bias -= self.lr * self.db\n",
    "        return self.dx  # 反向传播梯度\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):  # 无参数，不需初始化\n",
    "        pass\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.sigmoid(x)\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, d):\n",
    "        sig = self.sigmoid(self.x)\n",
    "        self.dx = d * sig * (1 - sig)\n",
    "        return self.dx  # 反向传递梯度\n",
    "\n",
    "\n",
    "class QuadraticLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        self.x = x\n",
    "        # 由于我们的label本身只包含一个数字，我们需要将其转换成和模型输出值尺寸相匹配的向量形式\n",
    "        self.label = np.zeros_like(x)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0  # 只有正确标签所代表的位置概率为1，其他为0\n",
    "        self.loss = np.sum(np.square(x - self.label)) / \\\n",
    "            self.x.shape[0] / 2  # 求平均后再除以2是为了表示方便\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self):\n",
    "        self.dx = (self.x - self.label) / self.x.shape[0]  # 2被抵消掉了\n",
    "        return self.dx\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        self.x = x\n",
    "        self.label = np.zeros_like(x)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0\n",
    "        # np.nan_to_num()避免log(0)得到负无穷的情况\n",
    "        self.loss = np.nan_to_num(-self.label *\n",
    "                                  np.log(x) - ((1 - self.label) * np.log(1 - x)))\n",
    "        self.loss = np.sum(self.loss) / x.shape[0]\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self):\n",
    "        self.dx = (self.x - self.label) / self.x / \\\n",
    "            (1 - self.x)  # 分母会与Sigmoid层中的对应部分抵消\n",
    "        return self.dx\n",
    "\n",
    "\n",
    "class Accuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):  # 只需forward\n",
    "        self.accuracy = np.sum(\n",
    "            [np.argmax(xx) == ll for xx, ll in zip(x, label)])  # 对预测正确的实例数求和\n",
    "        self.accuracy = 1.0 * self.accuracy / x.shape[0]\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hawaiian-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "loss: 0.630214458669289\n",
      "accuracy: 0.0412\n",
      "epochs: 1\n",
      "loss: 0.48027311132686334\n",
      "accuracy: 0.0662\n",
      "epochs: 2\n",
      "loss: 0.4782947706358594\n",
      "accuracy: 0.0405\n",
      "epochs: 3\n",
      "loss: 0.47534284719385606\n",
      "accuracy: 0.0691\n",
      "epochs: 4\n",
      "loss: 0.471010362060996\n",
      "accuracy: 0.0412\n",
      "epochs: 5\n",
      "loss: 0.46625704321856604\n",
      "accuracy: 0.1077\n",
      "epochs: 6\n",
      "loss: 0.4593167713345355\n",
      "accuracy: 0.1194\n",
      "epochs: 7\n",
      "loss: 0.4521781406223829\n",
      "accuracy: 0.1866\n",
      "epochs: 8\n",
      "loss: 0.4415712056666338\n",
      "accuracy: 0.1204\n",
      "epochs: 9\n",
      "loss: 0.4350049276649647\n",
      "accuracy: 0.3275\n",
      "epochs: 10\n",
      "loss: 0.4213039423067082\n",
      "accuracy: 0.2385\n",
      "epochs: 11\n",
      "loss: 0.4109893612684813\n",
      "accuracy: 0.3475\n",
      "epochs: 12\n",
      "loss: 0.3949866039069355\n",
      "accuracy: 0.4455\n",
      "epochs: 13\n",
      "loss: 0.37457157982689615\n",
      "accuracy: 0.3949\n",
      "epochs: 14\n",
      "loss: 0.3542813991536828\n",
      "accuracy: 0.4105\n",
      "epochs: 15\n",
      "loss: 0.3325247009155853\n",
      "accuracy: 0.392\n",
      "epochs: 16\n",
      "loss: 0.31118838012904754\n",
      "accuracy: 0.6353\n",
      "epochs: 17\n",
      "loss: 0.2827904923773702\n",
      "accuracy: 0.5971\n",
      "epochs: 18\n",
      "loss: 0.2599848604993026\n",
      "accuracy: 0.6999\n",
      "epochs: 19\n",
      "loss: 0.2402508566343445\n",
      "accuracy: 0.6589\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datalayer1 = Data('data/train.npy', 1024)  # 用于训练，batch_size设置为1024\n",
    "    # 用于验证，所以设置batch_size为10000,一次性计算所有的样例\n",
    "    datalayer2 = Data('data/validate.npy', 10000)\n",
    "    inner_layers = []\n",
    "    inner_layers.append(FullyConnect(17 * 17, 20))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    inner_layers.append(FullyConnect(20, 26))  # 增加一个隐层\n",
    "    inner_layers.append(Sigmoid())\n",
    "    losslayer = QuadraticLoss()\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    for layer in inner_layers:\n",
    "        layer.lr = 1000.0  # 为所有中间层设置学习速率\n",
    "\n",
    "    epochs = 20\n",
    "    for i in range(epochs):\n",
    "        print('epochs:', i)\n",
    "        losssum = 0\n",
    "        iters = 0\n",
    "        while True:\n",
    "            data, pos = datalayer1.forward()  # 从数据层取出数据\n",
    "            x, label = data\n",
    "            for layer in inner_layers:  # 前向计算\n",
    "                x = layer.forward(x)\n",
    "\n",
    "            loss = losslayer.forward(x, label)  # 调用损失层forward函数计算损失函数值\n",
    "            losssum += loss\n",
    "            iters += 1\n",
    "            d = losslayer.backward()  # 调用损失层backward函数曾计算将要反向传播的梯度\n",
    "\n",
    "            for layer in inner_layers[::-1]:  # 反向传播\n",
    "                d = layer.backward(d)\n",
    "\n",
    "            if pos == 0:  # 一个epoch完成后进行准确率测试\n",
    "                data, _ = datalayer2.forward()\n",
    "                x, label = data\n",
    "                for layer in inner_layers:\n",
    "                    x = layer.forward(x)\n",
    "                accu = accuracy.forward(x, label)  # 调用准确率层forward()函数求出准确率\n",
    "                print('loss:', losssum / iters)\n",
    "                print('accuracy:', accu)\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automatic-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "loss: 4.089140659629275\n",
      "accuracy: 0.6332\n",
      "epochs: 1\n",
      "loss: 2.622252312546044\n",
      "accuracy: 0.8384\n",
      "epochs: 2\n",
      "loss: 1.9187565336590375\n",
      "accuracy: 0.8608\n",
      "epochs: 3\n",
      "loss: 1.4983254214685229\n",
      "accuracy: 0.9065\n",
      "epochs: 4\n",
      "loss: 1.2147071766821589\n",
      "accuracy: 0.9462\n",
      "epochs: 5\n",
      "loss: 1.0107972006645318\n",
      "accuracy: 0.9477\n",
      "epochs: 6\n",
      "loss: 0.8556984805185829\n",
      "accuracy: 0.9591\n",
      "epochs: 7\n",
      "loss: 0.7396769749037955\n",
      "accuracy: 0.9609\n",
      "epochs: 8\n",
      "loss: 0.6482363670047515\n",
      "accuracy: 0.9645\n",
      "epochs: 9\n",
      "loss: 0.575212806737187\n",
      "accuracy: 0.9686\n",
      "epochs: 10\n",
      "loss: 0.5243189456596665\n",
      "accuracy: 0.9712\n",
      "epochs: 11\n",
      "loss: 0.4752971367790839\n",
      "accuracy: 0.9733\n",
      "epochs: 12\n",
      "loss: 0.43867731204574173\n",
      "accuracy: 0.9744\n",
      "epochs: 13\n",
      "loss: 0.4072197303314605\n",
      "accuracy: 0.9747\n",
      "epochs: 14\n",
      "loss: 0.3808470715239229\n",
      "accuracy: 0.9762\n",
      "epochs: 15\n",
      "loss: 0.36218208623563597\n",
      "accuracy: 0.9774\n",
      "epochs: 16\n",
      "loss: 0.3373145000418363\n",
      "accuracy: 0.9776\n",
      "epochs: 17\n",
      "loss: 0.3215880140523324\n",
      "accuracy: 0.9776\n",
      "epochs: 18\n",
      "loss: 0.304686626717045\n",
      "accuracy: 0.9783\n",
      "epochs: 19\n",
      "loss: 0.2919122954692537\n",
      "accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datalayer1 = Data('data/train.npy', 1024)  # 用于训练，batch_size设置为1024\n",
    "    # 用于验证，所以设置batch_size为10000,一次性计算所有的样例\n",
    "    datalayer2 = Data('data/validate.npy', 10000)\n",
    "    inner_layers = []\n",
    "    inner_layers.append(FullyConnect(17 * 17, 20))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    inner_layers.append(FullyConnect(20, 26))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    losslayer = CrossEntropyLoss()\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    for layer in inner_layers:\n",
    "        layer.lr = 1.0  # 为所有中间层设置学习速率\n",
    "\n",
    "    epochs = 20\n",
    "    for i in range(epochs):\n",
    "        print('epochs:', i)\n",
    "        losssum = 0\n",
    "        iters = 0\n",
    "        while True:\n",
    "            data, pos = datalayer1.forward()  # 从数据层取出数据\n",
    "            x, label = data\n",
    "            for layer in inner_layers:  # 前向计算\n",
    "                x = layer.forward(x)\n",
    "\n",
    "            loss = losslayer.forward(x, label)  # 调用损失层forward函数计算损失函数值\n",
    "            losssum += loss\n",
    "            iters += 1\n",
    "            d = losslayer.backward()  # 调用损失层backward函数曾计算将要反向传播的梯度\n",
    "\n",
    "            for layer in inner_layers[::-1]:  # 反向传播\n",
    "                d = layer.backward(d)\n",
    "\n",
    "            if pos == 0:  # 一个epoch完成后进行准确率测试\n",
    "                data, _ = datalayer2.forward()\n",
    "                x, label = data\n",
    "                for layer in inner_layers:\n",
    "                    x = layer.forward(x)\n",
    "                accu = accuracy.forward(x, label)  # 调用准确率层forward()函数求出准确率\n",
    "                print('loss:', losssum / iters)\n",
    "                print('accuracy:', accu)\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
