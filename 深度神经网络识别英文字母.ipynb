{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "internal-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, name, batch_size):  # 数据所在的文件名name和batch中图片的数量batch_size\n",
    "        with open(name, 'rb') as f:\n",
    "            data = np.load(f, allow_pickle=True)\n",
    "        self.x = data[0]  # 输入x\n",
    "        self.y = data[1]  # 预期正确输出y\n",
    "        self.l = len(self.x)\n",
    "        self.batch_size = batch_size\n",
    "        self.pos = 0  # pos用来记录数据读取的位置\n",
    "\n",
    "    def forward(self):\n",
    "        pos = self.pos\n",
    "        bat = self.batch_size\n",
    "        l = self.l\n",
    "        if pos + bat >= l:  # 已经是最后一个batch时，返回剩余的数据，并设置pos为开始位置0\n",
    "            ret = (self.x[pos:l], self.y[pos:l])\n",
    "            self.pos = 0\n",
    "            #print(l)\n",
    "            index = list(range(l))\n",
    "            np.random.shuffle(index)  # 将训练数据打乱\n",
    "            self.x = self.x[index]\n",
    "            self.y = self.y[index]\n",
    "        else:  # 不是最后一个batch, pos直接加上batch_size\n",
    "            ret = (self.x[pos:pos + bat], self.y[pos:pos + bat])\n",
    "            self.pos += self.batch_size\n",
    "\n",
    "        return ret, self.pos  # 返回的pos为0时代表一个epoch已经结束\n",
    "\n",
    "    def backward(self, d):  # 数据层无backward操作\n",
    "        pass\n",
    "\n",
    "\n",
    "class FullyConnect:\n",
    "    def __init__(self, l_x, l_y):  # 两个参数分别为输入层的长度和输出层的长度\n",
    "        # 使用随机数初始化参数，请暂时忽略这里为什么多了np.sqrt(l_x)\n",
    "        self.weights = np.random.randn(l_y, l_x) / np.sqrt(l_x)\n",
    "        self.bias = np.random.randn(l_y, 1)  # 使用随机数初始化参数\n",
    "        self.lr = 0  # 先将学习速率初始化为0，最后统一设置学习速率\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x  # 把中间结果保存下来，以备反向传播时使用\n",
    "        self.y = np.array([np.dot(self.weights, xx) +\n",
    "                           self.bias for xx in x])  # 计算全连接层的输出\n",
    "        return self.y  # 将这一层计算的结果向前传递\n",
    "\n",
    "    def backward(self, d):\n",
    "        # 根据链式法则，将反向传递回来的导数值乘以x，得到对参数的梯度\n",
    "        ddw = [np.dot(dd, xx.T) for dd, xx in zip(d, self.x)]\n",
    "        self.dw = np.sum(ddw, axis=0) / self.x.shape[0]\n",
    "        self.db = np.sum(d, axis=0) / self.x.shape[0]\n",
    "        self.dx = np.array([np.dot(self.weights.T, dd) for dd in d])\n",
    "\n",
    "        # 更新参数\n",
    "        self.weights -= self.lr * self.dw\n",
    "        self.bias -= self.lr * self.db\n",
    "        return self.dx  # 反向传播梯度\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):  # 无参数，不需初始化\n",
    "        pass\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.sigmoid(x)\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, d):\n",
    "        sig = self.sigmoid(self.x)\n",
    "        self.dx = d * sig * (1 - sig)\n",
    "        return self.dx  # 反向传递梯度\n",
    "\n",
    "\n",
    "class QuadraticLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        self.x = x\n",
    "        # 由于我们的label本身只包含一个数字，我们需要将其转换成和模型输出值尺寸相匹配的向量形式\n",
    "        self.label = np.zeros_like(x)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0  # 只有正确标签所代表的位置概率为1，其他为0\n",
    "        self.loss = np.sum(np.square(x - self.label)) / \\\n",
    "            self.x.shape[0] / 2  # 求平均后再除以2是为了表示方便\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self):\n",
    "        self.dx = (self.x - self.label) / self.x.shape[0]  # 2被抵消掉了\n",
    "        return self.dx\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        self.x = x\n",
    "        self.label = np.zeros_like(x)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0\n",
    "        # np.nan_to_num()避免log(0)得到负无穷的情况\n",
    "        self.loss = np.nan_to_num(-self.label *\n",
    "                                  np.log(x) - ((1 - self.label) * np.log(1 - x)))\n",
    "        self.loss = np.sum(self.loss) / x.shape[0]\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self):\n",
    "        self.dx = (self.x - self.label) / self.x / \\\n",
    "            (1 - self.x)  # 分母会与Sigmoid层中的对应部分抵消\n",
    "        return self.dx\n",
    "\n",
    "\n",
    "class Accuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):  # 只需forward\n",
    "        self.accuracy = np.sum(\n",
    "            [np.argmax(xx) == ll for xx, ll in zip(x, label)])  # 对预测正确的实例数求和\n",
    "        self.accuracy = 1.0 * self.accuracy / x.shape[0]\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hawaiian-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "loss: 0.6686726098567513\n",
      "accuracy: 0.0412\n",
      "epochs: 1\n",
      "loss: 0.47914464787070565\n",
      "accuracy: 0.0851\n",
      "epochs: 2\n",
      "loss: 0.47680071025218707\n",
      "accuracy: 0.0773\n",
      "epochs: 3\n",
      "loss: 0.4749066880696405\n",
      "accuracy: 0.1272\n",
      "epochs: 4\n",
      "loss: 0.47192767159637816\n",
      "accuracy: 0.1099\n",
      "epochs: 5\n",
      "loss: 0.4676032212886114\n",
      "accuracy: 0.1412\n",
      "epochs: 6\n",
      "loss: 0.46278017712438\n",
      "accuracy: 0.1361\n",
      "epochs: 7\n",
      "loss: 0.45782305049488325\n",
      "accuracy: 0.2231\n",
      "epochs: 8\n",
      "loss: 0.4495597076376573\n",
      "accuracy: 0.1799\n",
      "epochs: 9\n",
      "loss: 0.4392585486579413\n",
      "accuracy: 0.182\n",
      "epochs: 10\n",
      "loss: 0.42677384832574033\n",
      "accuracy: 0.1608\n",
      "epochs: 11\n",
      "loss: 0.4105813816659786\n",
      "accuracy: 0.2507\n",
      "epochs: 12\n",
      "loss: 0.3907906784688003\n",
      "accuracy: 0.363\n",
      "epochs: 13\n",
      "loss: 0.3695177958161556\n",
      "accuracy: 0.4291\n",
      "epochs: 14\n",
      "loss: 0.3450764232457108\n",
      "accuracy: 0.5126\n",
      "epochs: 15\n",
      "loss: 0.3197228415481909\n",
      "accuracy: 0.564\n",
      "epochs: 16\n",
      "loss: 0.2942202357357132\n",
      "accuracy: 0.5445\n",
      "epochs: 17\n",
      "loss: 0.27071342437497303\n",
      "accuracy: 0.8052\n",
      "epochs: 18\n",
      "loss: 0.24600949728295243\n",
      "accuracy: 0.706\n",
      "epochs: 19\n",
      "loss: 0.2314475231304313\n",
      "accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datalayer1 = Data('train.npy', 1024)  # 用于训练，batch_size设置为1024\n",
    "    # 用于验证，所以设置batch_size为10000,一次性计算所有的样例\n",
    "    datalayer2 = Data('validate.npy', 10000)\n",
    "    inner_layers = []\n",
    "    inner_layers.append(FullyConnect(17 * 17, 20))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    inner_layers.append(FullyConnect(20, 26))  # 增加一个隐层\n",
    "    inner_layers.append(Sigmoid())\n",
    "    losslayer = QuadraticLoss()\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    for layer in inner_layers:\n",
    "        layer.lr = 1000.0  # 为所有中间层设置学习速率\n",
    "\n",
    "    epochs = 20\n",
    "    for i in range(epochs):\n",
    "        print('epochs:', i)\n",
    "        losssum = 0\n",
    "        iters = 0\n",
    "        while True:\n",
    "            data, pos = datalayer1.forward()  # 从数据层取出数据\n",
    "            x, label = data\n",
    "            for layer in inner_layers:  # 前向计算\n",
    "                x = layer.forward(x)\n",
    "\n",
    "            loss = losslayer.forward(x, label)  # 调用损失层forward函数计算损失函数值\n",
    "            losssum += loss\n",
    "            iters += 1\n",
    "            d = losslayer.backward()  # 调用损失层backward函数曾计算将要反向传播的梯度\n",
    "\n",
    "            for layer in inner_layers[::-1]:  # 反向传播\n",
    "                d = layer.backward(d)\n",
    "\n",
    "            if pos == 0:  # 一个epoch完成后进行准确率测试\n",
    "                data, _ = datalayer2.forward()\n",
    "                x, label = data\n",
    "                for layer in inner_layers:\n",
    "                    x = layer.forward(x)\n",
    "                accu = accuracy.forward(x, label)  # 调用准确率层forward()函数求出准确率\n",
    "                print('loss:', losssum / iters)\n",
    "                print('accuracy:', accu)\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automatic-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "40000\n",
      "10000\n",
      "loss: 4.160684276783156\n",
      "accuracy: 0.6718\n",
      "epochs: 1\n",
      "40000\n",
      "10000\n",
      "loss: 2.5638589841778145\n",
      "accuracy: 0.8419\n",
      "epochs: 2\n",
      "40000\n",
      "10000\n",
      "loss: 1.8171986568529275\n",
      "accuracy: 0.886\n",
      "epochs: 3\n",
      "40000\n",
      "10000\n",
      "loss: 1.3797041122038667\n",
      "accuracy: 0.88\n",
      "epochs: 4\n",
      "40000\n",
      "10000\n",
      "loss: 1.110182744504591\n",
      "accuracy: 0.929\n",
      "epochs: 5\n",
      "40000\n",
      "10000\n",
      "loss: 0.9277701204606699\n",
      "accuracy: 0.9215\n",
      "epochs: 6\n",
      "40000\n",
      "10000\n",
      "loss: 0.7902215108749843\n",
      "accuracy: 0.9565\n",
      "epochs: 7\n",
      "40000\n",
      "10000\n",
      "loss: 0.6818410930780067\n",
      "accuracy: 0.9651\n",
      "epochs: 8\n",
      "40000\n",
      "10000\n",
      "loss: 0.6028708329207292\n",
      "accuracy: 0.9672\n",
      "epochs: 9\n",
      "40000\n",
      "10000\n",
      "loss: 0.5361771524321332\n",
      "accuracy: 0.9683\n",
      "epochs: 10\n",
      "40000\n",
      "10000\n",
      "loss: 0.48188016305929826\n",
      "accuracy: 0.9714\n",
      "epochs: 11\n",
      "40000\n",
      "10000\n",
      "loss: 0.44192276724657054\n",
      "accuracy: 0.9734\n",
      "epochs: 12\n",
      "40000\n",
      "10000\n",
      "loss: 0.4065413197099986\n",
      "accuracy: 0.9733\n",
      "epochs: 13\n",
      "40000\n",
      "10000\n",
      "loss: 0.37564265966107585\n",
      "accuracy: 0.9745\n",
      "epochs: 14\n",
      "40000\n",
      "10000\n",
      "loss: 0.35623272951281426\n",
      "accuracy: 0.9764\n",
      "epochs: 15\n",
      "40000\n",
      "10000\n",
      "loss: 0.33545696182550094\n",
      "accuracy: 0.9768\n",
      "epochs: 16\n",
      "40000\n",
      "10000\n",
      "loss: 0.3244372600479505\n",
      "accuracy: 0.9774\n",
      "epochs: 17\n",
      "40000\n",
      "10000\n",
      "loss: 0.30461136881725015\n",
      "accuracy: 0.9792\n",
      "epochs: 18\n",
      "40000\n",
      "10000\n",
      "loss: 0.2861724208916806\n",
      "accuracy: 0.98\n",
      "epochs: 19\n",
      "40000\n",
      "10000\n",
      "loss: 0.272466699166176\n",
      "accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datalayer1 = Data('train.npy', 1024)  # 用于训练，batch_size设置为1024\n",
    "    # 用于验证，所以设置batch_size为10000,一次性计算所有的样例\n",
    "    datalayer2 = Data('validate.npy', 10000)\n",
    "    inner_layers = []\n",
    "    inner_layers.append(FullyConnect(17 * 17, 20))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    inner_layers.append(FullyConnect(20, 26))\n",
    "    inner_layers.append(Sigmoid())\n",
    "    losslayer = CrossEntropyLoss()\n",
    "    accuracy = Accuracy()\n",
    "\n",
    "    for layer in inner_layers:\n",
    "        layer.lr = 1.0  # 为所有中间层设置学习速率\n",
    "\n",
    "    epochs = 20\n",
    "    for i in range(epochs):\n",
    "        print('epochs:', i)\n",
    "        losssum = 0\n",
    "        iters = 0\n",
    "        while True:\n",
    "            data, pos = datalayer1.forward()  # 从数据层取出数据\n",
    "            x, label = data\n",
    "            for layer in inner_layers:  # 前向计算\n",
    "                x = layer.forward(x)\n",
    "\n",
    "            loss = losslayer.forward(x, label)  # 调用损失层forward函数计算损失函数值\n",
    "            losssum += loss\n",
    "            iters += 1\n",
    "            d = losslayer.backward()  # 调用损失层backward函数曾计算将要反向传播的梯度\n",
    "\n",
    "            for layer in inner_layers[::-1]:  # 反向传播\n",
    "                d = layer.backward(d)\n",
    "\n",
    "            if pos == 0:  # 一个epoch完成后进行准确率测试\n",
    "                data, _ = datalayer2.forward()\n",
    "                x, label = data\n",
    "                for layer in inner_layers:\n",
    "                    x = layer.forward(x)\n",
    "                accu = accuracy.forward(x, label)  # 调用准确率层forward()函数求出准确率\n",
    "                print('loss:', losssum / iters)\n",
    "                print('accuracy:', accu)\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
